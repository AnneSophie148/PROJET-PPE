UTF-8 and Unicode

   Unicode Transformation Format 8-bit is a variable-width encoding that
   can represent every character in the Unicode character set. It was
   designed for backward compatibility with ASCII and to avoid the
   complications of endianness and byte order marks in UTF-16 and UTF-32.
   ^[1]

   UTF-8 encodes each Unicode character as a variable number of 1 to 4
   octets, where the number of octets depends on the integer value
   assigned to the Unicode character. It is an efficient encoding of
   Unicode documents that use mostly US-ASCII characters because it
   represents each character in the range U+0000 through U+007F as a
   single octet.

   UTF-8 is the default encoding for XML and since 2010 has become the
   dominant character set on the Web.

Standards

     * RFC 3629: UTF-8, a transformation format of ISO 10646. November
       2003.
     * The Unicode Standard 5.0, November 2006. [purchase from Amazon.com]
          + In particular, see the informal description of UTF-8 in
            sections 2.5 and 2.6, pages 30-32, and a much more formal
            definition in sections 3.9 and 3.10, pages 77-81.

Articles and background reading

     * UTF-8 and Unicode FAQ for Unix/Linux by Markus Kuhn
     * Forms of Unicode, an excellent overview by Mark Davis
     * Wikipedia UTF-8 contains a good discussion of why five- and
       six-octet sequences are now illegal UTF-8
     * Unicode Transformation Formats [czyborra.com]
     * The Absolute Minimum Every Software Developer Absolutely,
       Positively Must Know About Unicode and Character Sets (No
       Excuses!), an amusing and informative article by Joel Spolsky

Character Sets

   The MIME character set attribute for UTF-8 is UTF-8. Character sets are
   case-insensitive, so utf-8 is equally valid. [IANA Character Sets].

   In a modern HTML 5 page, place this tag inside <head> ... </head>:
<meta charset="UTF-8">

   In an XML prolog, the encoding is typically specified as an attribute:
<?xml version="1.0" encoding="UTF-8" ?>
     __________________________________________________________________

   Last modified: Wed Jan 5 12:57:21 PST 2022

   #alternate Feed para ZUM » Feed de comentários para ZUM » Feed de
   comentários para ZUM » Deep Nostalgia e o falseamento profundo da
   história pelas IAs alternate alternate alternate

   [tr?id=1510141622751967&ev=PageView&noscript=1]

ZUM - revista de fotografia

     * Português
          + Inglês

   ____________________ Ok
   assine a newsletter ZUM

   (BUTTON)
     * Revista ZUM
          + Sumários
          + Artigos Online
          + ZUM na Escola
     * Festival ZUM 2022
          + Programação 2022
          + Feira de Fotolivros 2022
          + Convocatória de Fotolivros 2022
          + Festival ZUM 2021
          + Programação 2021
          + Convocatória de Fotolivros 2021
          + Festival ZUM 2020
          + Programação 2020
          + Festival ZUM 2019
          + Programação 2019
          + Convocatória de Fotolivros
          + Feira de Fotolivros
          + Ocupação Videobrasil
          + Festival ZUM 2018
          + Programação 2018
          + Convocatória de Fotolivros
          + Feira de fotolivros
          + Festival ZUM 2017
          + Programação
          + Convocatória de Fotolivros
          + Festival ZUM 2016
     * Bolsa ZUM 2022
          + Glicéria Tupinambá
          + Igi Ayedun
          + Bolsa ZUM 2021
          + Castiel Vitorino Brasileiro
          + Tiago Sant´Ana
          + Bolsistas 2020
          + Rafael BQueer
          + Val Souza
          + Bolsistas 2019
          + Aleta Valente
          + Eustáquio Neves
          + Bolsistas de 2018
          + Aline Motta
          + Dias & Riedweg
          + Bolsistas de 2017
          + Dora Longo Bahia
          + Vijai Patchineelam
          + Bolsistas de 2016
          + Sofia Borges
          + Tatewaki Nio
          + Bolsistas de 2015
          + Bárbara Wagner
          + João Castilho
          + Bolsistas de 2014
          + Coletivo Trëma
          + Coletivo Garapa
          + Bolsistas de 2013
          + Letícia Ramos
          + Helena Martins-Costa
     * Colunistas
          + Giselle Beiguelman
          + Jorge Bodanzky
          + Moacir dos Anjos
          + Lilia Schwarcz
          + Ronaldo Entler
          + Dorrit Harazim
          + Geoff Dyer
     * Radar
          + Artigos
          + Entrevistas
          + Notícias
          + Galeria
          + Por Trás da Foto
     * Livros
          + Resenhas
          + Fotolivro de Cabeceira
     * Exposições
          + Resenhas
          + Brasil
          + Mundo
          + IMS
     * Sobre
     * Índice
     * Projetos
          + Offside Brazil
          + Água escondida
          + Brasil: o espetáculo do crescimento
          + TV ZUM
          + Câmera Aberta

   Colunistas

Deep Nostalgia e o falseamento profundo da história pelas IAs

   Giselle Beiguelman Publicado em: 10 de março de 2021
   (BUTTON)
     *
     *


   Imagem dos avós da autora (circa 1916) com colorização retrospectiva
   feita com IA no aplicativo MyHeritage que usa tecnologia DeOldify.

   Há uma febre de aplicativos para tridimensionalizar, colorizar, animar
   fotos antigas e dar “vida” ao passado. Loopsie, Colorize e Deep
   Nostalgia são alguns deles. Todos funcionam bem. Rápidos e fáceis de
   usar, escondem um meticuloso trabalho com Inteligência Artificial.
   Acontece, porém, que a história tratada como gadget é um problema.
   Os resultados obtidos usando cada um desses aplicativos são sempre
   muito parecidos. Em consequência, nos vemos diante de um emergente
   conjunto de passados fictícios e muito semelhantes: felizes e
   “liberados” dos supostos defeitos do tempo. Melhorias na qualidade das
   imagens apagam dobras e manchas causadas pela idade; enquanto
   colorizações retrospectivas deixam tudo e todos com uma paleta que
   oscila entre cores pastel e tons outonais.

   Em todos esses softwares o processamento das imagens é feito a partir
   de técnicas de deep learning que, por meio de redes neurais, transferem
   estilos e comportamentos para as imagens. Para tanto, dezenas de
   milhares de imagens são usadas para treinar os algoritmos que dão cor,
   movimento e profundidade às fotos e vídeos que inserimos em cada um
   desses aplicativos. No caso do “viral do momento”, o Deep Nostalgia,
   que teve mais de 60 milhões de downloads logo após o lançamento em 27
   de fevereiro, fotos antigas, de antepassados a personalidades
   históricas, ganham expressões que vão de piscadas a giros de cabeça,
   passando por sorrisos e olhos arregalados. No passado ninguém chorava?
   Ninguém ficava triste?


   Obviamente que sim. Mas o “cardápio” de movimentos é pré-definido e
   feito a partir de vídeos “contentes” gravados com funcionários da
   MyHeritage, a empresa que disponibiliza o Deep Nostalgia, desenvolvido
   pela israelense D-Id, especializada em tecnologia de reencenação
   facial. Importante sublinhar que todo o processo está a anos luz de
   distância de tradicionais recursos de pós-produção e edição. Estamos
   falando de procedimentos de aprendizado de máquina em que os algoritmos
   são programados para reconhecer padrões (como a geometria das linhas do
   rosto, os movimentos labiais e até a voz) e então transferi-los de uma
   imagem a outra.

   Expliquei mais detalhadamente esse processo de entender o que são e
   como funcionam os deepfakes em um artigo sobre deepfakes publicado na
   ZUM #18. Basicamente são imagens produzidas com Inteligência
   Artificial, utilizando aprendizagem de máquina para substituir, de
   forma automatizada, rostos e também usar vozes humanas sincronizados
   com movimentos labiais e gestuais. Alguns exemplos recentes são a
   mensagem de ano novo da Rainha Elizabeth, veiculada pelo Channel 4, e o
   perfil do TikTok que gera vídeos de Tom Cruise nas mais inusitadas
   situações.

   No caso do Deep Nostalgia, a técnica retoma os princípios do deepfake,
   mas de forma ainda mais sofisticada. Seu algoritmo é construído com
   diversas redes neurais profundas, treinadas com datasets de muitos
   milhares de vídeos. Ao “encontrar” uma imagem inserida no aplicativo, o
   algoritmo busca um vídeo pré-gravado da sua base de dados e calcula um
   mapa de movimento para interpolar os seus pixels na foto estática. Um
   mapa de oclusão (os dados sobre a iluminação da imagem) “fabrica” as
   partes faltantes na foto, revelando dentes e a lateral da cabeça, entre
   outros aspectos que não estão presentes na foto original adicionada ao
   sistema. É essa odisseia computacional que produz, em segundos, a
   aparência natural das animações que tomaram conta das redes sociais na
   última semana.

   Glitches e bugs a parte (os vídeos às vezes apresentam alguns elementos
   desajeitados, como borrões em rostos com barba e perda de foco), são
   comuns as reações de encantamento de milhões de usuários. Há também os
   que se sentem extremamente perturbados por essas imagens assombradas
   pela Inteligência Artificial. Os motivos de horror, geralmente, vêm da
   sensação de ver os mortos ganhando vida subitamente.

   Acrescento a esse leque de sensações mais uma: o da perturbação frente
   à pasteurização da história. Muito embora não exista intenção de
   convencer ninguém que as fotos animadas sejam vídeos que ressuscitam
   gestos dos falecidos, não são poucos os usuários que acreditam que esse
   deepfake mimetize de fato um ente querido ou uma personalidade
   importante. A ilusão se torna ainda mais problemática pelo fato de que
   quanto mais se alimenta o sistema, mais ele aprende com seus próprios
   erros e se aprimora, diminuindo bastante eventuais falhas de
   processamento ainda apresentadas. Com isso, reconfiguram-se as posições
   na curva emocional de nossa relação com esse tipo de imagem e nos
   aproximando de seres artificiais.

   Essa curva emocional é central a uma teoria estética da robótica, a do
   “vale da estranheza” (uncanny valley), de autoria do roboticista
   japonês Masahiro Mori, criador do ASIMO, entre outros robôs famosos. De
   acordo com essa teoria, entes tecnológicos parecidos com humanos tendem
   a gerar repulsa. Mas, paradoxalmente, quanto mais semelhantes eles são,
   tendem a gerar empatia. A teoria de Mori é dos anos 1970 e tem recebido
   várias atualizações para comprovar sua hipótese. Partindo desse ponto
   de vista, a relação com entes artificiais que ressurgem de um passado
   nunca ocorrido se torna ainda mais complexa.

   O aprendizado de máquina é, substancialmente, a acurácia no
   estabelecimento e reconhecimento de padrões. O que não cabe no padrão é
   considerado ruído e descartado. Basta olhar para pelo menos três vídeos
   feitos com o Deep Nostalgia para notar que os movimentos são sempre os
   mesmos. Mas o que aconteceria se esse tipo de padronização maquínica se
   sofisticar ao ponto de ser culturalmente tomado como referência?

   Há uma inequívoca tendência para o que chamo de eugenia do olhar
   embarcada nos processos de sintetização de imagens por IAs. E não é por
   acaso que os retratos compostos de Francis Galton (1822-1911), pai da
   eugenia, sejam tão semelhantes aos vetores que processam os algoritmos
   de Reconhecimento Facial (os eigenvectors, tema para uma outra coluna).
   Há também uma inegável possibilidade de consolidação de novos
   negacionismos, capazes de emplacar as mais estapafúrdias teses.


   IFRAME:
   https://www.youtube.com/embed/nGWVn1xnMIg?start=25&feature=oembed

   Esse, aliás, foi o mote da instalação In Event of Moon Disaster (No
   caso de um desastre lunar, 2019), criada por Francesca Panetta,
   diretora de criação do Centro para Virtualidade Avançada do MIT. Nela,
   o presidente Richard Nixon reporta, diretamente do Salão Oval da Casa
   Branca, o desastre ocorrido com a Apolo 11. Tal discurso foi escrito
   por Bill Saphire e seria lido no caso de um acidente com a missão lunar
   que, como se sabe, não aconteceu. Para sua obra, Panetta utilizou
   discursos anteriores de Nixon gravados em vídeo para transferir suas
   expressões faciais e movimentos labiais ao seu clone e, assim,
   sintetizar uma inédita peça audiovisual com sua voz, dicção e
   semblante, proferindo palavras que ele nunca disse sobre um fato que
   nunca ocorreu. Para além de sua impactante plasticidade, a obra
   funciona como uma alerta sobre os potenciais estragos dos deepfakes no
   plano do revisionismo histórico.

   Há cerca de 20 anos, nos primórdios da febre retrô que tomou o design e
   o mundo do entretenimento, o crítico T. J. Clark escreveu que se
   antigamente as mercadorias vendiam promessas de futuro, hoje elas
   existem “para inventar uma história, um tempo perdido de intimidade e
   estabilidade, de que todo mundo afirma se lembrar, mas que ninguém
   teve.” Clark identificava essa necessidade de inventar um passado com
   uma crise do tempo, marcado pela “tentativa de expulsar da consciência
   a banalidade do presente” (Modernismos, 2007, p. 322-323).

   Antes dele, Umberto Eco, em um clássico dos anos 1980, Viagem na
   irrealidade cotidiana, mostrava que esse tipo de movimentação pavimenta
   também “uma filosofia da imortalidade enquanto duplicação”. Como se não
   pudéssemos conviver com o passado e só fosse possível fazer sua cópia,
   não sua preservação pela memória.

   Essas considerações são importantes porque situam esse fenômeno da
   nostalgia do que nunca fomos em um contexto mais amplo. Contudo, a
   “gadgetização” da história que aplicativos como Deep Nostalgia promovem
   aparece em um momento particular da pandemia. Nele se cruzam a
   aceleração do cotidiano pela digitalização da vida com a perda de
   horizontes do porvir plasmado pela resiliência da covid-19.

   De um lado, forja-se o presente com um tempo assombrado pelo falso e
   pelo vintage, no qual o passado cumpre apenas a função de fornecer uma
   capa divertida ao agora. De outro, temos uma experiência do futuro que
   funciona como parênteses, uma bolha suspensa, impossível de ser
   conectada ao vivido. Nessa curiosa temporalidade tudo parece ser
   passível de ser recuperado e recompor-se ao sabor de um padrão
   configurado por uma IA. Que historiografia, que cultura visual está
   sendo escrita nas linhas de seus códigos e suas memórias de botox? ///


   Giselle Beiguelman é colunista do site da ZUM, artista e professora da
   FAUUSP. Assina também a coluna Ouvir Imagens na Rádio USP e é autora
   de Memória da amnésia: políticas do esquecimento (2019), entre outros.
   Entre seus projetos recentes, destacam-se Odiolândia (2017), Memória da
   Amnésia (2015) e a curadoria de Arquinterface: a cidade expandida pelas
   redes (2015).



   Tags: deep nostalgia, Deepfake, Inteligência artificial

Leia também

     * Por uma botânica rebelde Por uma botânica rebelde
     * Racismo algorítmico Racismo algorítmico
     * Tá na cara! O Big Brother virou Big Data Tá na cara! O Big Brother
       virou Big Data
     * O futuro das rugas O futuro das rugas
     * Inteligência artificial, racismo e misoginia na automatização da
       visão Inteligência artificial, racismo e misoginia na automatização
       da visão
     * Profundamente falsa: a imagem na era da pós-verdade Profundamente
       falsa: a imagem na era da pós-verdade
     __________________________________________________________________

   Site da revista ZUM, a publicação semestral do Instituto Moreira Salles
   dedicada ao universo fotográfico

Links

     * Revista ZUM
     * Assine
     * Subscribe
     * Compre | BUY
     * Contato | CONTACT
     * Newsletter ZUM
